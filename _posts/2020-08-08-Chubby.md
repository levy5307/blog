---
layout: post
title: Chubby
date: 2020-08-08
Author: Levy5307
tags: [论文]
comments: true
toc: true
---

## 一致性client库 or 分布式锁

chubby实现的是一个中心化锁所服务，基于其一些优势:
1. 服务改造的时候，直接用分布式锁更容易实现
2. 许多服务有小数据存储的要求，chubby提供了小数据存储
3. 对大部分程序员更熟悉锁
4. 一致性client库需要client拥有多台机器来做投票选举

## 粗粒度锁 or 细粒度锁

细粒度锁指的是只会持有锁很短的时间（秒级或更短），而粗粒度锁指的是持有比较长的时间，比如说是用于选主，通常都会是几小时甚至几天。这两种粒度的锁对锁服务提出了不同的要求。

粗粒度的锁因为隔很长的时间才需要访问锁服务一次，所以对server端的负载压力很小，并且这个负载跟client端的处理速率关联很小（意思是即使client端每秒处理很多请求，锁服务的server端收到的请求速率也不会明显增加）。另外，锁服务server端的机器故障对client的影响也比较小。

细粒度的锁就完全相反了，server端的失败可能造成很多client阻塞。性能和扩容的能力都很重要，因为server端的负载和client的处理速率密切相关。
Chubby只试图提供粗粒度的锁，客户端也可以直接根据他们的应用实现细粒度锁。

## 系统结构

![系统结构图](../images/chubby-cell.jpg)

Chubby主要有两个组成部分，server和client library。Chubby的一个个cell中有五台server组成一个集群，其中一个master，其他为slave。五台机器按照Paxos协议选举出master，要想成为master必须得到五台中大多数的投票。master会以租约的形式运行，只要它能得到副本的同意（即续租），那么租约便能定时更新然后延长master的运行时间。

客户端会向DNS请求Chubby服务器列表，然后随机发起访问，非master服务器会依据自身的存储的集群信息向客户端反馈哪台是master，然后客户端重定向到master。

如果一个副本挂了，并且几个小时都没有恢复，一个替换系统就会选一台新机器，启动chubby服务，然后更新DNS table。master会定期从DNS table拉数据，就会得知这个变化，然后在数据库中更新cell成员的列表，这个列表也是通过普通的一致性协议在副本间维护一致性的。

与此同时，新的副本会从存储在文件系统的数据库备份中取得最近几次的拷贝，并且在活跃的的那些副本那里取得更新。等这个机器成功处理了master的一个等待commit的请求后（说明此时数据已经是最新了），这个机器就可以参与投票了。

## 文件、目录

chubby的文件与unix文件系统基本一样，这样的好处是chubby文件既可以被chubby api访问，也可以被其他文件系统（例如GFS）的api访问。

```
/ls/foo/wombat/pouch
```

ls即lock service，是所有Chubby的文件名字通用的前缀，并且代表了锁服务。第二个组件（foo）是Chubby cell的名字

有临时和永久的节点，所有节点都可以被显示的删除，临时节点当没有client打开它们时就会被自动删除，所以临时的节点可以被用来检测client是否存活。
