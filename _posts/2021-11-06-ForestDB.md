---
layout: post
title: ForestDB
date: 2021-11-06
Author: levy5307
tags: [论文]
comments: true
toc: true
---

在过去几年中，数据管理应用正在发生巨大的变化。例如Facebook和Twitter等社交应用，其用户数和处理的数据量变的越来越大，并且为了灵活分析，数据正在变得非结构化。不幸的是，由于关系型数据库的扩展性和严格的data model，使得使用关系型数据库变得非常挣扎，由于这个原因，很多公司开始开发NoSQL数据库。

尽管现在对于sharding、data replication、distributed caching有很多中NoSQL技术，而底层的存储引擎却没有什么不同。每个节点都是用KV存储引擎以一种schema-less的形式存储数据，其中key和value都是不定长的。由于kv存储引擎直接与存储设备（HDD或者SSD）交互，所以其吞吐和延迟决定着整个系统的性能。

kv存储引擎的吞吐量和延迟受存储访问时间的限制，而该存储访问时间由两个因素决定：

1. 每次kv操作所访问的block数量。其由索引结构和特征所决定的

2. block访问模式，其由数据是如何读取及写入引擎有关。

目前有两种比较流行的索引结构：B+-tree和LSM-tree。B+-tree是最流行的索引结构，由于其最小化IO操作数量的特性，广泛应用于各种传统的数据库。现代key-value数据库例如BerkeleyDB、Couchbase、InnoDB和MongoDB使用B+-tree。相较于B+-tree，LSM-tree以牺牲读性能来提高写性能，很多最新系统例如LevelDB、RocksDB、SQLite、Cassandra和BigTable使用LSM-tree或者其变种。

尽管这些树型结构目前已经很成功了，但是相较于固定长度key，当key长度可变时其表现的就很差了。因为当key长度边长时，如果node大小不变，那么fanout degree将会减少（fanout degree是指一个节点中的key-pointer对数量），因此对于维持相同的数据量，***树的高度则会变高***。另外，如果想要保持相同fanout degree，***那么node大小则会变大***，因此每个node所需要读取或者写入的block数量也会变多。很不幸的，由于平均磁盘访问数量和树的磁盘空间占用，直接受树的高度和节点大小的影响，因此随着key变长，其性能也跟着降级。

为了解决这个问题，BerkeleyDB和LevelDB使用了前缀压缩技术，然而，这很大程度上受到key模式的影响。如果key在key空间随机分布，那么key剩余的未压缩空间仍然很长，因此前缀压缩带来的收益很小。我们需要设计一种更有效的方法来索引变长key。

同时，磁盘访问方式是kv存储设计的另外一个关键因素。update-in-place提供了较高的读性能，但是损失写性能，因此不适合写密集型应用。因此，很多数据库使用append-only或者WAL来顺序写入磁盘block。这种设计可以达到很高的写吞吐，但是却要遭到compaction带来的开销。这种开销的大小与每个索引操作的平均访问block数和索引结构所占用的总体空间密切相关，因为在compaction过程中执行了许多合并操作。

这篇论文主要讲述了ForestDB，一个用于下一代Couchbase的KV存储引擎。为了以高效利用时间和空间的方式检索变长key，提出了Hierarchical B+-tree-based trie（HB+-trie）。为了实现高读取和写入吞吐，以及支持高并发访问，索引更新以append-only的形式写入存储设备中。这同样简化了on-disk结构，以实现MVCC。最后我们实现了ForestDB，其吞吐显著高于LevelDB、RocksDB和Couchstore

## Background

