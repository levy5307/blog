---
layout: post
title: Snowflake
date: 2022-05-02
Author: levy5307
tags: [论文]
comments: true
toc: true
---

## Introduction

云技术来临了，然而传统的数仓是在云时代之前创建的，他们被设计为在小型静态集群上运行，其架构完全不适合云。

不仅平台发生了改变，数据也在改变。过去数仓要处理的数据主要来自于组织内部，他们的结构、容量和产生速度都是可预知的。随着云技术的发展，大量且快速增长的数据来自于不容易控制的外部，而且经常以schema-less、半结构化的格式存储。面对这些数据时，传统数仓则明显力不从心。

为了应对这些缺点，部分数仓社区已经转向Hadoop或Spark等大数据平台。尽管这些工具是不可或缺的，开源社区也在不断地进行重大改进，如Stinger Initiative（号称让Hive提速100倍），但它们仍然缺乏现有数仓的效率和功能。但最重要的是，他们需要大量的努力来推广和使用。

Snowflake是真正利用云设施的经济、弹性、服务化等优点的数仓产品。它的关键特性如下：

- ***纯正的SaaS体验***

用户不需要关心机器、运维、调优、扩容，只要数据上传到Snowflake，立即就可以开始分析。

- ***Retional***

支持ANSI SQL和ACID的事务。大部分用户几乎无需改动或者很小的改动就可以迁移其workloads

- ***Semi-Structured*** 

Snowflake提供了用于遍历、展平和嵌套半结构化数据的内置函数和SQL扩展，并支持JSON和Avro等流行格式。自动模式发现和列式存储使得对schema较少的半结构化数据的操作几乎与对普通关系数据的操作一样快，而无需用户额外的操作

- ***Elastic*** 

存储和计算资源可以独立地、无缝地扩展，而不影响数据可用性或者并发查询的性能。

- ***Highly Available*** 

Snowflake能够容忍节点，集群，甚至全部的数据中心失败。在软件和硬件更新的时候不会下线。

- ***Durable***

Snowflake的设计具使数据具有极高的持久性，并具有防止意外数据丢失的额外保障：克隆、下线和跨区域备份。

- ***Cost-efficient***

Snowflake具有很高的计算效率，所有的表数据都被压缩。用户只为他们实际使用的存储和计算资源付费

- ***Secure***

所有数据包括临时文件和网络流量都是端到端加密的。没有用户数据暴露在云平台上。此外，基于角色的访问控制使用户能够在SQL级别执行级别细粒度的访问

## Storage v.s. Compute

Shared-nothing结构已经成为高性能数据仓库的主流体系结构，主要原因有两个：可扩展性和商用硬件。在Shared-nothing结构中，每个查询处理器节点都有自己的本地磁盘。表是跨节点水平分区的，每个节点只负责其本地磁盘上的rows。这种设计可以很好地扩展星型模式查询，因为将一个小的（广播的）维度表与一个大的（分区的）事实表进行join需要很少的带宽。而且，由于共享数据结构或硬件资源几乎没有争用，因此不需要昂贵的定制硬件。

在Shared-nothing结构中，每个节点都有相同的功能并在相同的硬件上运行。这种结构设计无疑是良好的。不过有一个重要的缺点：它将***计算资源和存储资源紧密耦合***，这在某些场景中会导致问题：

- ***Heterogeneous Workload***

尽管硬件是同构的，然而workload却不是。对bulk load（高IO带宽，轻计算）场景很适合的配置，却不适合负载查询（低IO、重计算），反之亦然。这使得硬件总体利用率不高

- ***Membership Changes***

如果发生节点更改、节点故障，或是用户主动进行了系统调整，则大量数据需要reshuffle。由于相同的节点同时负责数据reshuffle和查询，因此会对性能有显著的影响，从而限制了灵活性和可用性。

- ***Online Upgrade***

各种资源耦合在一起，并且是同质化的，因此在线升级想要完全不影响系统变得很困难。

在on-premise环境中（内部部署），这些问题都可以忍受。虽然负载是异构的，但是仅有固定、少量的节点池可供选择，你也没什么可做的。另外升级、扩容或者节点故障发生的概率很低。

但是在云上情况则大不相同了：

- 像Amazon EC2这样的平台上拥有多种多样的节点类型。要利用其优势，只需要将数据带到正确类型的节点上。

- 节点故障更为频繁，会导致性能发生巨大变化。membership的改变不是偶然，而是常态。

- 在线升级和弹性扩展逐渐成为了当下客户的一个重大痛点。在线升级能够大幅缩短软件开发周期，提升系统的可用性

基于此，Snowflake实现了存储和计算分离。存储和计算由两个松耦合、独立可扩展的服务来处理。计算是通过Snowflake专有的shared-nothing引擎提供。存储是通过亚马逊S3提供的，同时支持多类型的对象存储（Azure 对象存储，Google云存储）。

并且每个计算节点在本地磁盘上（推荐SSD）缓存了一些表的数据，这样做有两个好处：

- 减少计算节点和存储节点之间的网络流量

- 实现了数据的冷热分离，本地磁盘空间不用存储整个数据，这些数据可能非常大，而且大部分是冷数据（很少访问）。本地磁盘专门用于临时数据和缓存，两者都是热数据。因此，缓存了热数据，性能就接近甚至超过纯shared-nothing结构的性能。

我们称这种新的体系结构为multi-cluster、 shared-data结构。

## Architecture

Snowflake的目标是成为企业级的服务，除了易用性和相互操作性之外，还需要有高可用性。整个Snowflake分为三层：

- Data Storage

该层使用Amazon S3来存储table data和query result

- Virtual Warehouses

系统的“肌肉”。该层通过弹性的虚拟集群（称为virtual warehouse），执行查询

- Cloud Services

系统的“大脑”。这一层是管理virtual warehouse、查询、事务和围绕virtual warehouse的所有元数据的服务的集合，包含数据库元信息、访问控制信息、加密密钥、使用情况统计等。

![](../images/snowflake-arch.jpg)

### Data Storage

AWS被选为Snowflake的初始平台主要有两个原因。首先，AWS是云平台市场上最成熟的产品。其次（与第一点相关），AWS提供了最大的潜在用户资源。

在S3或者使用HDFS等类似技术开发自己的存储服务的选择中，Snowflake发现S3虽然性能不太稳定，但它的易用性、高可用、强数据可靠性都是很难被替代的。因此Snowflake没有开发自己的存储服务，转而将精力花在了VW层的本地cache和弹性处理倾斜的技术上了。

S3有如下特点：

- 相对local storage，延迟高，并且有比较高的CPU负载，尤其在使用HTTPS时。

- 文件只能覆盖写，不能追加写

- GET支持读部分文件

这些属性对Snowflake的table file format和并发控制方案有很大的影响。表被水平地划分成大的、不可变的文件，这些文件相当于传统数据库系统中的block或page。在每个文件中，每个属性或列的值都被分组在一起并进行了大量压缩。每个表文件都有一个file header，其中包含文件中每列的偏移量，以及其他元数据。因为S3允许对部分文件执行GET请求，所以查询只需要下载文件头和它们需要的列。

snowflake不仅在表数据上使用S3。当本地磁盘空间耗尽时，它还使用S3存储由查询（例如，大量连接）生成的临时数据，以及大型查询结果。将temp数据溢出到S3，系统可以计算任意大的查询，而不会出现内存不足或磁盘不足的错误。将查询结果存储在S3中，实现了客户端交互新方式并简化查询处理，因为不再需要像传统数据库那样在server端维护query的游标了。

元数据，例如catalog信息，由S3文件、统计信息、锁、事务日志等组成，存储在可伸缩的事务KV存储中，这也是云服务的一部分。

### Virtual Warehouse

虚拟仓库层由EC2实例集群组成。每个这样的集群通过一个称为虚拟仓库（VW）的抽象呈现给用户。构成虚拟仓库的单个EC2实例称为工作节点。用户不需要关心哪个或者多少个工作节点组成了一个虚拟仓库。虚拟仓库按照大家所熟悉的“T恤尺寸”从X-Small到XX-Large来标识规模大小。这种抽象允许Snowflake独立演进服务和定价，而不会与具体的云服务绑定。

#### Elasticity and Isolation

VM层是纯计算资源，可以按照需求创建、销毁并且可以随时改变大小。创建或者销毁一个VM对数据库状态没有任何影响。当没有查询时候，用户可以关闭所有的VM资源。这种弹性容许用户独立于数据层，按照需求动态的伸缩他们的计算资源。

***每个query只会在一个VW上运行。work nodes不会在VW之间共享，从而使查询具有强大性能隔离***（snowflake将工作节点共享视为未来工作的重点，因为对于性能隔离不太重要的用例，它将实现更高的利用率和更低的成本）

VW在处理query时会在每个参与的worker node上创建一个新worker进程，这个进程会在query结束后就停止。因为表文件都是不可变的，worker进程不会破坏DB状态，挂掉后直接重试即可。目前Snowflake还没有实现部分重试，而是有节点挂掉则整个query重试。

每个用户可以在任何给定的时间运行多个VW，而每个VW又可以运行多个并发查询。每个VW都可以访问相同的共享表，而无需物理复制数据。

***数据共享意味着用户可以share/integrate自己的所有数据，而计算私有则意味着不同负载和组织之间不会有相互影响***，这也是数据仓库的核心原则之一。这种弹性和隔离使得一些新的使用策略成为可能。对于Snowflake的用户来说为不同目的的queries准备多个VW是很正常的，偶尔还会按需创建VW来执行Bulk Load之类的任务。

Snowflake的弹性还使得同样的价格下用户可以享受到好很多的性能。比如同样的导数据任务，4个节点的系统可能要15小时，而32个节点的系统只要2小时，两者的价格差不多，但后者的体验好很多。弹性VW就是Snowflake最大的优势和差异点之一。

#### Local Caching and File Stealing

每个节点的本地盘会作为表文件的cache，保存访问过的S3对象，包含file header和访问过的列，并使用LRU策略淘汰数据。

cache的生命期与worker节点的生命周期相同，被这个节点上的所有进程和所有query共享。

为了提升命中率，减少不必要的cache，query优化器会使用一致性哈希，根据表文件名将文件分配给各个节点，后续需要读这些文件的query会被优先发给对应节点。

Snowflake中一致的hash是lazy的。当工作节点由于节点故障或VW大小调整而更改时，不会立即对数据进行shuffle。相反，Snowflake依赖LRU替换策略最终替换缓存内容。此解决方案将替换缓存内容的成本分摊到多个查询上，从而获得更好的可用性，并简化了系统。

此外，数据倾斜的处理在云数仓中尤为重要。由于虚拟化问题或者网络争用，某些节点的执行速度可能比其他节点慢很多。Snowflake的做法是当一个worker进程A处理完所有文件后，它会从其它进程那里偷一个文件过来，目标进程B如果此时有多个文件待处理，就会同意这次请求，之后进程A会直接从S3上下载这个文件，而不是从进程B那里，避免使B更慢。该过程叫做File Stealing

#### Execution Engine

虽然可伸缩性是首要的，但每个节点的效率同样重要。Snowflake希望给用户提供市场上任何数据库服务产品中最好的性价比，因此我们决定实现我们自己的SQL执行引擎。Snowflake构建的引擎是列式的、向量化的和基于push的

***Columnar***

列存在分析场景的优势是更高效地使用CPU cache、SIMD，有更多机会使用（轻量）压缩。

***Vectorized***

Snowflake不会物化中间结果，而是流水线处理，每次批量处理列存格式的数千行数据，节省了I/O，还显著提升了cache效率。

***Push-based***

上游算子会将它的结果直接推给下游，而不是等着下游来拉（传统的Volcano模型）。这种方式能提升cache效率，因为它从密集循环中移除了控制流逻辑，也允许更高效地处理DAG形状的执行计划

同时Snowflake中也没有传统引擎会有的一些开销，如:

- query过程面对的是一组固定的不可变文件（S3中的文件不可修改），因此不需要事务管理，也不需要buffer pool。

- Snowflake允许所有主要算子（join/group by/sort）溢写到磁盘上。纯内存引擎虽然更精简、也许更快，但是限制性太强，无法处理所有的查询情况，毕竟分析型workload有时候会有大量的join或aggregation

### Cloud Services

